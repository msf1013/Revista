USE revista;

-- Datos de tabla Revista.
INSERT INTO Revista VALUES(1, '2015-05-22', 'Carta Editor 1: He aquí el primer tomo digital, gracias por su apoyo y espero disfruten de la revista.');
INSERT INTO Revista VALUES(2, '2015-06-19', 'Carta Editor 2: En este segundo tomo tenemos más material que espero sea de su interés. Como siempre, disfruten de la revista.');
INSERT INTO Revista VALUES(3, '2015-07-24', 'Carta Editor 3: Les traemos de nueva cuenta lo último en desarrollo tecnológico en este tomo realmente espectacular.');
INSERT INTO Revista VALUES(4, '2015-08-21', 'Carta Editor 4: Una vez más con sólo lo mejor que la industria tiene para ofrecer.');
INSERT INTO Revista VALUES(5, '2015-09-18', 'Carta Editor 5: A casi 6 meses del inicio de la revista digital, les traemos este tomo especial.');

-- Datos de tabla Cuenta.
INSERT INTO Cuenta VALUES(1, 'David Miguel', 'Gutíerrez Sánchez', 'davidmgs@gmail.com', 'dmgsadmin', '2014-06-05', 'Administrador');
INSERT INTO Cuenta VALUES(2, 'Esther', 'Cervantes Martínez', 'esther_cerv@hotmail.com', 'ecmescr', '2014-08-28', 'Escritor');
INSERT INTO Cuenta VALUES(3, 'Jesús Alejandro', 'Rodríguez González', 'chuy_alexrg@gmail.com', 'jargescr', '2014-09-16', 'Escritor');
INSERT INTO Cuenta VALUES(4, 'Ana Carolina', 'Peña Flores', 'anacaropf@hotmail.com', 'acpfescr', '2014-11-02', 'Escritor');
INSERT INTO Cuenta VALUES(5, 'Manuel Eduardo', 'Aguilar García', 'maneduag@gmail.com', 'meagsusc', '2015-03-27', 'Suscriptor');
INSERT INTO Cuenta VALUES(6, 'María Laura', 'Montes Suárez', 'mlaurams@hotmail.com', 'mlmssusc', '2015-01-12', 'Suscriptor');
INSERT INTO Cuenta VALUES(7, 'Edgar Felipe', 'Cantú Montemayor', 'edcantu@gmail.com', 'efcmsusc', '2015-04-02', 'Suscriptor');
INSERT INTO Cuenta VALUES(8, 'Lorena Esperanza', 'Silva Mendoza', 'lore_silva@hotmail.com', 'lesmjuez', '2014-08-13', 'Juez');
INSERT INTO Cuenta VALUES(9, 'José Ricardo', 'Pérez Juárez', 'rickyper@gmail.com', 'jrpjjuez', '2014-08-13', 'Juez');
INSERT INTO Cuenta VALUES(10, 'Patricia Gabriela', 'Ríos Alvarez', 'patyrios@hotmail.com', 'pgrajuez', '2014-08-13', 'Juez');
INSERT INTO Cuenta VALUES(11, 'Héctor Ariel', 'Govea Mata', 'hector.govmata@gmail.com', 'hagmjuez', '2014-08-13', 'Juez');
INSERT INTO Cuenta VALUES(12, 'Carla Mariana', 'Treviño Lozano', 'mari_tre@hotmail.com', 'cmtljuez', '2014-08-13', 'Juez');
INSERT INTO Cuenta VALUES(13, 'Roberto Rafael', 'Salas Muñoz', 'rrsalas@gmail.com', 'rrsmjuez', '2014-08-13', 'Juez');
INSERT INTO Cuenta VALUES(14, 'Jessica Daniela', 'Morales López', 'jessy_morales@hotmail.com', 'jdmljuez', '2014-08-13', 'Juez');
INSERT INTO Cuenta VALUES(15, 'Carlos Andrés', 'Guajardo Solís', 'charlie.gs@gmail.com', 'cagsjuez', '2014-08-13', 'Juez');

-- Datos de tabla Suscriptor.
INSERT INTO Suscriptor VALUES(5, false, false, true, 'Digital', '2015-02-28', '2016-02-27', '8776-4132-2215', 'BBVA Bancomer', 800, 'Topolobampo 3514, Col. Las Brisas', NULL);
INSERT INTO Suscriptor VALUES(6, true, true, false, 'Digital/Fisica', '2014-08-30', '2015-08-29', '2345-9574-1354', 'Banorte', 1400, 'Junco de la Vega 2209, Villa Florida', NULL);
INSERT INTO Suscriptor VALUES(7, true, false, false, 'Digital/Fisica', '2014-08-30', '2015-08-29', '2345-9574-1354', 'Banorte', 1400, 'Junco de la Vega 2209, Villa Florida', 6);

-- Datos de tabla Juez.
INSERT INTO Juez VALUES(8, 1);
INSERT INTO Juez VALUES(9, 2);
INSERT INTO Juez VALUES(10, 3);
INSERT INTO Juez VALUES(11, 4);
INSERT INTO Juez VALUES(12, 5);
INSERT INTO Juez VALUES(13, 6);
INSERT INTO Juez VALUES(14, 7);
INSERT INTO Juez VALUES(15, 8);

-- Datos de tabla Administrador.
INSERT INTO Administrador VALUES(1);

-- Datos de tabla Escritor.
INSERT INTO Escritor VALUES(2, '2015-05-22');
INSERT INTO Escritor VALUES(3, '2015-09-18');
INSERT INTO Escritor VALUES(4, '2015-07-24');

-- Datos de tabla Orden.
INSERT INTO Orden VALUES(1, 240, false, false, 3, 5);
INSERT INTO Orden VALUES(2, 400, true, false, 5, 5);
INSERT INTO Orden VALUES(3, 80, true, true, 1, 6);
INSERT INTO Orden VALUES(4, 240, false, false, 3, 6);
INSERT INTO Orden VALUES(5, 160, true, false, 2, 7);
INSERT INTO Orden VALUES(6, 320, true, true, 4, 7);

-- Datos de tabla RevistaOrden.
INSERT INTO RevistaOrden VALUES(1, 1, 2);
INSERT INTO RevistaOrden VALUES(2, 1, 1);
INSERT INTO RevistaOrden VALUES(1, 2, 1);
INSERT INTO RevistaOrden VALUES(2, 2, 1);
INSERT INTO RevistaOrden VALUES(3, 2, 1);
INSERT INTO RevistaOrden VALUES(4, 2, 1);
INSERT INTO RevistaOrden VALUES(5, 2, 1);
INSERT INTO RevistaOrden VALUES(4, 3, 1);
INSERT INTO RevistaOrden VALUES(2, 4, 3);
INSERT INTO RevistaOrden VALUES(1, 5, 1);
INSERT INTO RevistaOrden VALUES(5, 5, 1);
INSERT INTO RevistaOrden VALUES(2, 6, 3);
INSERT INTO RevistaOrden VALUES(3, 6, 1);

-- Datos de tabla ArticuloPendiente.
INSERT INTO ArticuloPendiente VALUES(1, 'CyberCode: augmented reality environment', 'ID-AWARE AUGMENTED ENVIRONMENTS In designing augmented reality systems, it is often essential to implement a tagging (ID) system to make a link between physical and digital spaces. Some examples of tagged IDs are barcodes [18, 11, 9, 6], radio-frequency (RF) tags [2, 23], resonant tags [13], and infrared IDs [22].1 Unlike the digital links or icons on the computer screen, these tags are tangible, can be manipulated physically, and can be used in real-world contexts (e.g., installed in a building, attached to a wall, or printed on a book). When these tags are part of our physical environment, devices with a tag reader can retrieve digital information from them [18, 10], activate associated actions, or attach information to them [17]. Thesetags can also be used as operands for direct-manipulation operations. For example, a user picks-up data from a printed document, and drops it on the nearby printer. This operation can be realized by recognizing an ID on the document and an ID on the printer. This is a “physically” extended concept of drag-and-drop, an interaction technique commonly used at computer GUIs.', 'The CyberCode is a visual tagging system based on a 2Dbarcode technology and provides several features not provided by other tagging systems. CyberCode tags can be recognized by the low-cost CMOS or CCD cameras found in more and more mobile devices, and it can also be used to determine the 3D position of the tagged object as well as its ID number. This paper describes examples of augmented reality applications based on CyberCode, and discusses some key characteristics of tagging technologies that must be taken into account when designing augmented reality environments.', '2015-09-18', 'Rechazado', '2015-02-22', false, 2);
INSERT INTO ArticuloPendiente VALUES(2, 'Virtual reality for the mining industry', 'Users can interact with the virtual worlds via a variety of hardware devices (e.g. joysticks and data gloves), and the impression of actually being in the virtual world (immersion) can be created and enhanced by special optical and audio devices (e.g. head-mounted displays and 3D sound). Virtual reality originally denoted a fully immersive system, although it has since been used to describe systems lacking cybergloves and head-mounted displays. Non-immersive virtual reality uses a computer monitor and the user interacts with the system using a joystick, mouse or keyboard. VR systems are real-time computer simulations of the real world, in which visual realism, object behaviour and user interaction are essential elements [Denby and Schofield 1999; Orr et al. 2002]. Modern simulation systems range from tactile systems that physically represent the real world through to purely computergenerated visualisations. These computer-generated, threedimensional, artificial worlds are commonly referred to as Virtual Environments (VE), and in many cases users are able to interact with the data and images that are presented by these computer-based visual systems. In a mining context, a primary aim of developing virtual environments is to allow mine personnel to practise and experience mine situations, activities and processes that can be encountered in the day to day operations at a mining site. Safe and efficient planning and production are fundamental to profitable mine operations and VR provides an intuitive means of exploring the diverse and disparate information associated with mining processes.', 'Virtual reality is a rapidly growing technology which utilises the ever-increasing power of computers to simulate real-world and imaginary environments and situations with a high degree of realism and interactiveness.', '2015-05-22', 'Aceptado', '2014-12-17', true, 2);
INSERT INTO ArticuloPendiente VALUES(3, 'Frequent subgraph mining on single graph', 'Frequent pattern mining has attracted a lot of research in recent years. Many efficient algorithms have been developed for mining frequent itemsets [26, 27, 28, 29], sequential patterns [31, 32], and trees [33, 34]. However, we may be required to find more complicated structures like graphs in some applications. Most works being done on frequent subgraph mining are focused on graph transactions. Examples include gSpan [22], FSG [12]. FFSM[8], MolFea [35], MoSS [36] and Gaston[18]. Holder et al. proposed SUBDUE [6] to discover the best compressing structures. Inokuchi et al. [8] proposed an Apriori based algorithm to discover all frequent substructures. Coatney et al. [2] developed MotifMiner to discover common substructures in Biochemical Molecules. Cong et al. [3] applied frequent substructures discovery in Hierarchical semi-structured data. Bordino et al. introduced large networks mining with subgraph counting in [1]. In many applications, we need to find frequent subgraphs in a single large graph, for instance, discovering structural regularities or anomalies in social network or web structures, which are single graphs and we do not want to split them into parts. However, the algorithms for mining graph transactions cannot be directly used to mine in a single graph even though finding frequent subgraphs in a single graph is more general and applicable [15]. Jiang et al. in [37] try to find globally frequent subgraphs on a single labeled graph. The method that they use is to split the single graph into a set of smaller graphs, and then perform frequent subgraph mining on the smaller graphs. As a result, they are still doing traditional frequent subgraph mining on graph transactions. One drawback of their approach is that they only count once even if more than one instance exists in one smaller graph. Therefore their algorithm will miss some true frequent subgraphs that have many instances in one smaller graph.', 'Frequent subgraph mining has always been an important issue in data mining. Several frequent graph mining methods have been developed for mining graph transactions. However, these methods become less usable when the dataset is a single large graph. Also, when the graph is too large to fit in main memory, alternative techniques are necessary to efficiently find frequent subgraphs. We investigate the task of frequent subgraph mining on a single large graph using sampling approaches and find that sampling is a feasible approach for this task. We evaluate different sampling methods and provide a novel sampling method called random areas selection sampling, which produces better results than all the current graph sampling approaches with customized parameters.', '2015-08-21', 'Aceptado', '2015-05-20', true, 3);
INSERT INTO ArticuloPendiente VALUES(4, 'Querying graphs with uncertain predicate', 'Uncertainty is a challenging problem in graph analysis. Graph research has addressed many ways uncertainty can complicate a network. Some works focus on how to model uncertainty on a graph [4], [3]. Others have developed algorithms to query an uncertain graph [12]. Another research problem is to clean or interpolate uncertain or missing values [10]. As far as we know, one less explored but equally important problem is the uncertain query. Outside of a network, an example of an uncertain query is when the exact spelling of a word is uncertain. This problem is well studied, for example [7], and its solution is utilized in many search engines. In a network setting, this problem occurs, for example, when an analyst is unsure of the connectivity or the attribute values on the nodes and edges of a sub-network she would like to find in a network. There are several motivating applications for this type of uncertainty.', 'In many applications the available data give rise to an attributed graph, with the nodes corresponding to the entities of interest, edges to their relationships and attributes on both provide additional characteristics. To mine such data structures we have proposed a visual analytic algebra that enhances the atomic operators of selection, aggregation and a visualization step that allows the user to interact with the data. However, in many settings the user has a certain degree of uncertainty about the desired query; the problem is further compounded if the final results are the product of a series of such uncertain queries. To address this issue, we introduce a probabilistic framework that incorporates uncertainty in the queries and provides a probabilistic assessment of the likelihood of the obtained outcomes. We discuss its technical characteristics and illustrate it on a number of examples.', '2015-09-18', 'Aceptado', '2015-04-15', true, 3);
INSERT INTO ArticuloPendiente VALUES(5, 'Support for Big Datas Limiting Resource', 'A common assumption in complex work domains is that more data availability naturally leads to operational benefit [6]. Big Data extends this intent by adding larger volumes of data, a broader spectrum of data types, and faster streaming data ingest. With this increase in data volume, variety, and velocity Big Data advances are focused on technologies such as data gathering, processing, storage, and computing resource management to keep pace with the “fire-hose” of data. Additionally, the Big Data community has focused largely on the use of Analytics to discover insights in the data, which are then reported back to the end user as the analytic output. McAfee & Brynjolfsson [4] give example use cases where analytic processing on historical Big Data provided insights into historical truth, which were then used as a basis for future decision-making. More real-time uses of analytics are also employed as observed by RCS engineers in recent projects where real-time streaming analytics were used to discover new instances of already known signatures. This tech-centered approach to Big Data can be beneficial when historical evidence provides a good grounding for future decision-making, or where interesting patterns and behaviors are known ahead of time. However, in domains like Intelligence Analysis, Business Analysis, and other complex domains, history is not necessarily a good indicator of future, and patterns and signatures that are interesting evolve and change with the situation and are often times by definition unknown ahead of time. This indicates that effective attention direction support systems must be robust enough to handle unpredicted, novel, or unforeseen circumstances, circumstances that were not identified through pre-analysis.', 'With an increase in data volume, variety, and velocity, Big Data advances tend to focus on technologies such as data gathering, processing, data storage, and analytics, all of which assume that technology is the limiting factor in leveraging Big Data to its fullest potential. The research framework proposed here takes a more holistic look at the Joint Cognitive System, identifying human attention as the limiting resource for employing Big Data for operational use. The framework leverages prior research in attention management, sensory perception, and joint cognitive systems to lay out a Human Centered Big Data Research agenda for designing attention direction support in Big Data environments.', '2015-09-18', 'En Revision', '2015-06-02', false, 4);
INSERT INTO ArticuloPendiente VALUES(6, 'Primitives for non-block data structures', 'Building a library of concurrent data structures is an essential way to simplify the difficult task of developing concurrent software. There are many lock-based data structures, but locks are not fault-tolerant and are susceptible to problems such as deadlock [11]. It is often preferable to use hardware synchronization primitives like compare-and-swap (CAS) instead of locks. However, the difficulty of this task has inhibited the development of non-blocking data structures. These are data structures which guarantee that some operation will eventually complete even if some processes crash. Our goal is to facilitate the implementation of high-performance, provably correct, non-blocking data structures on any system that supports a hardware CAS instruction. We introduce three new operations, load-link-extended (LLX), validate-extended (VLX) and store-conditional-extended (SCX), which are natural generalizations of the well known load-link (LL), validate (VL) and store-conditional (SC) operations. We provide a practical implementation of our new operations from CAS. Complete proofs of correctness appear in [7]. We also show how these operations make the implementation of non-blocking data structures and their proofs of correctness substantially less difficult, as compared to using LL, VL, SC, and CAS directly.', 'We define a new set of primitive operations that greatly simplify the implementation of non-blocking data structures in asynchronous shared-memory systems. The new operations operate on a set of Data-records, each of which contains multiple fields. The operations are generalizations of the well-known load-link (LL) and store-conditional (SC) operations called LLX and SCX. The LLX operation takes a snapshot of one Data-record. An SCX operation by a process p succeeds only if no Data-record in a specified set has been changed since p last performed an LLX on it. If successful, the SCX atomically updates one specific field of a Data-record in the set and prevents any future changes to some specified subset of those Data-records. We provide a provably correct implementation of these new primitives from single-word compare-and-swap. As a simple example, we show how to implement a non-blocking multiset data structure in a straightforward way using LLX and SCX.', '2015-07-24', 'Aceptado', '2015-02-22', true, 4);

-- Datos de tabla Votos.
INSERT INTO Votos VALUES(1, 8, true);
INSERT INTO Votos VALUES(1, 9, true);
INSERT INTO Votos VALUES(1, 10, true);
INSERT INTO Votos VALUES(1, 11, true);
INSERT INTO Votos VALUES(1, 12, false);
INSERT INTO Votos VALUES(1, 13, false);
INSERT INTO Votos VALUES(1, 14, false);
INSERT INTO Votos VALUES(1, 15, false);
INSERT INTO Votos VALUES(2, 8, true);
INSERT INTO Votos VALUES(2, 9, true);
INSERT INTO Votos VALUES(2, 10, false);
INSERT INTO Votos VALUES(2, 11, true);
INSERT INTO Votos VALUES(2, 12, true);
INSERT INTO Votos VALUES(2, 13, false);
INSERT INTO Votos VALUES(2, 14, true);
INSERT INTO Votos VALUES(2, 15, true);
INSERT INTO Votos VALUES(3, 8, true);
INSERT INTO Votos VALUES(3, 9, true);
INSERT INTO Votos VALUES(3, 10, true);
INSERT INTO Votos VALUES(3, 11, true);
INSERT INTO Votos VALUES(3, 12, true);
INSERT INTO Votos VALUES(3, 13, true);
INSERT INTO Votos VALUES(3, 14, false);
INSERT INTO Votos VALUES(3, 15, true);
INSERT INTO Votos VALUES(4, 8, false);
INSERT INTO Votos VALUES(4, 9, true);
INSERT INTO Votos VALUES(4, 10, true);
INSERT INTO Votos VALUES(4, 11, false);
INSERT INTO Votos VALUES(4, 12, true);
INSERT INTO Votos VALUES(4, 13, true);
INSERT INTO Votos VALUES(4, 14, false);
INSERT INTO Votos VALUES(4, 15, true);
INSERT INTO Votos VALUES(5, 8, true);
INSERT INTO Votos VALUES(5, 10, false);
INSERT INTO Votos VALUES(5, 11, true);
INSERT INTO Votos VALUES(5, 12, true);
INSERT INTO Votos VALUES(5, 15, false);
INSERT INTO Votos VALUES(6, 8, true);
INSERT INTO Votos VALUES(6, 9, true);
INSERT INTO Votos VALUES(6, 10, true);
INSERT INTO Votos VALUES(6, 11, true);
INSERT INTO Votos VALUES(6, 12, true);
INSERT INTO Votos VALUES(6, 13, true);
INSERT INTO Votos VALUES(6, 14, true);
INSERT INTO Votos VALUES(6, 15, true);

-- Datos de tabla Comentarios.
INSERT INTO Comentarios VALUES(1, 10, 'Me parece un tema interesante, innovador y de suma importancia en el área.');
INSERT INTO Comentarios VALUES(2, 14, 'Un muy buen trabajo que refleja una inquietud constante en el área.');
INSERT INTO Comentarios VALUES(3, 12, 'Aunque tiene ciertas fallas de estilo, el contenido es muy bueno.');
INSERT INTO Comentarios VALUES(4, 11, 'Es totalmente superficial, falta ahondar mucho más en el tema.');
INSERT INTO Comentarios VALUES(5, 15, 'Me parece que el tono no va de acuerdo a la línea editorial de la revista.');
INSERT INTO Comentarios VALUES(6, 9, 'Excelente artículo, entretenido, educador y al grano en los detalles.');

-- Datos de tabla Articulo.
INSERT INTO Articulo VALUES(1, 1, 'Virtual reality for the mining industry', 'Users can interact with the virtual worlds via a variety of hardware devices (e.g. joysticks and data gloves), and the impression of actually being in the virtual world (immersion) can be created and enhanced by special optical and audio devices (e.g. head-mounted displays and 3D sound). Virtual reality originally denoted a fully immersive system, although it has since been used to describe systems lacking cybergloves and head-mounted displays. Non-immersive virtual reality uses a computer monitor and the user interacts with the system using a joystick, mouse or keyboard. VR systems are real-time computer simulations of the real world, in which visual realism, object behaviour and user interaction are essential elements [Denby and Schofield 1999; Orr et al. 2002]. Modern simulation systems range from tactile systems that physically represent the real world through to purely computergenerated visualisations. These computer-generated, threedimensional, artificial worlds are commonly referred to as Virtual Environments (VE), and in many cases users are able to interact with the data and images that are presented by these computer-based visual systems. In a mining context, a primary aim of developing virtual environments is to allow mine personnel to practise and experience mine situations, activities and processes that can be encountered in the day to day operations at a mining site. Safe and efficient planning and production are fundamental to profitable mine operations and VR provides an intuitive means of exploring the diverse and disparate information associated with mining processes.', 'Virtual reality is a rapidly growing technology which utilises the ever-increasing power of computers to simulate real-world and imaginary environments and situations with a high degree of realism and interactiveness.', 2, '2014-01-15', NULL);
INSERT INTO Articulo VALUES(2, 4, 'Frequent subgraph mining on single graph', 'Frequent pattern mining has attracted a lot of research in recent years. Many efficient algorithms have been developed for mining frequent itemsets [26, 27, 28, 29], sequential patterns [31, 32], and trees [33, 34]. However, we may be required to find more complicated structures like graphs in some applications. Most works being done on frequent subgraph mining are focused on graph transactions. Examples include gSpan [22], FSG [12]. FFSM[8], MolFea [35], MoSS [36] and Gaston[18]. Holder et al. proposed SUBDUE [6] to discover the best compressing structures. Inokuchi et al. [8] proposed an Apriori based algorithm to discover all frequent substructures. Coatney et al. [2] developed MotifMiner to discover common substructures in Biochemical Molecules. Cong et al. [3] applied frequent substructures discovery in Hierarchical semi-structured data. Bordino et al. introduced large networks mining with subgraph counting in [1]. In many applications, we need to find frequent subgraphs in a single large graph, for instance, discovering structural regularities or anomalies in social network or web structures, which are single graphs and we do not want to split them into parts. However, the algorithms for mining graph transactions cannot be directly used to mine in a single graph even though finding frequent subgraphs in a single graph is more general and applicable [15]. Jiang et al. in [37] try to find globally frequent subgraphs on a single labeled graph. The method that they use is to split the single graph into a set of smaller graphs, and then perform frequent subgraph mining on the smaller graphs. As a result, they are still doing traditional frequent subgraph mining on graph transactions. One drawback of their approach is that they only count once even if more than one instance exists in one smaller graph. Therefore their algorithm will miss some true frequent subgraphs that have many instances in one smaller graph.', 'Frequent subgraph mining has always been an important issue in data mining. Several frequent graph mining methods have been developed for mining graph transactions. However, these methods become less usable when the dataset is a single large graph. Also, when the graph is too large to fit in main memory, alternative techniques are necessary to efficiently find frequent subgraphs. We investigate the task of frequent subgraph mining on a single large graph using sampling approaches and find that sampling is a feasible approach for this task. We evaluate different sampling methods and provide a novel sampling method called random areas selection sampling, which produces better results than all the current graph sampling approaches with customized parameters.', 3, '2015-04-01', NULL);
INSERT INTO Articulo VALUES(3, 5, 'Querying graphs with uncertain predicate', 'Uncertainty is a challenging problem in graph analysis. Graph research has addressed many ways uncertainty can complicate a network. Some works focus on how to model uncertainty on a graph [4], [3]. Others have developed algorithms to query an uncertain graph [12]. Another research problem is to clean or interpolate uncertain or missing values [10]. As far as we know, one less explored but equally important problem is the uncertain query. Outside of a network, an example of an uncertain query is when the exact spelling of a word is uncertain. This problem is well studied, for example [7], and its solution is utilized in many search engines. In a network setting, this problem occurs, for example, when an analyst is unsure of the connectivity or the attribute values on the nodes and edges of a sub-network she would like to find in a network. There are several motivating applications for this type of uncertainty.', 'In many applications the available data give rise to an attributed graph, with the nodes corresponding to the entities of interest, edges to their relationships and attributes on both provide additional characteristics. To mine such data structures we have proposed a visual analytic algebra that enhances the atomic operators of selection, aggregation and a visualization step that allows the user to interact with the data. However, in many settings the user has a certain degree of uncertainty about the desired query; the problem is further compounded if the final results are the product of a series of such uncertain queries. To address this issue, we introduce a probabilistic framework that incorporates uncertainty in the queries and provides a probabilistic assessment of the likelihood of the obtained outcomes. We discuss its technical characteristics and illustrate it on a number of examples.', 4, '2015-05-03', 2);
INSERT INTO Articulo VALUES(4, 3, 'Primitives for non-block data structures', 'Building a library of concurrent data structures is an essential way to simplify the difficult task of developing concurrent software. There are many lock-based data structures, but locks are not fault-tolerant and are susceptible to problems such as deadlock [11]. It is often preferable to use hardware synchronization primitives like compare-and-swap (CAS) instead of locks. However, the difficulty of this task has inhibited the development of non-blocking data structures. These are data structures which guarantee that some operation will eventually complete even if some processes crash. Our goal is to facilitate the implementation of high-performance, provably correct, non-blocking data structures on any system that supports a hardware CAS instruction. We introduce three new operations, load-link-extended (LLX), validate-extended (VLX) and store-conditional-extended (SCX), which are natural generalizations of the well known load-link (LL), validate (VL) and store-conditional (SC) operations. We provide a practical implementation of our new operations from CAS. Complete proofs of correctness appear in [7]. We also show how these operations make the implementation of non-blocking data structures and their proofs of correctness substantially less difficult, as compared to using LL, VL, SC, and CAS directly.', 'We define a new set of primitive operations that greatly simplify the implementation of non-blocking data structures in asynchronous shared-memory systems. The new operations operate on a set of Data-records, each of which contains multiple fields. The operations are generalizations of the well-known load-link (LL) and store-conditional (SC) operations called LLX and SCX. The LLX operation takes a snapshot of one Data-record. An SCX operation by a process p succeeds only if no Data-record in a specified set has been changed since p last performed an LLX on it. If successful, the SCX atomically updates one specific field of a Data-record in the set and prevents any future changes to some specified subset of those Data-records. We provide a provably correct implementation of these new primitives from single-word compare-and-swap. As a simple example, we show how to implement a non-blocking multiset data structure in a straightforward way using LLX and SCX.', 6, '2015-03-30', NULL);

-- Datos de tabla Resumen.
INSERT INTO Resumen VALUES(1, 1, 'El texto describe a la realidad virtual como implementación para la mejora de seguridad en la industria minera, desde entrenamiento hasta aplicación.');
INSERT INTO Resumen VALUES(2, 2, 'El artículo desmenuza técnicas relativamente simples para lograr la búsqueda de subgrafos menores en un grafo grande.');
INSERT INTO Resumen VALUES(3, 3, 'Este artículo busca dar un primer paso a la resolución del problema que representa la búsqueda dentro de grafos que son inciertos.');
INSERT INTO Resumen VALUES(4, 4, 'Este texto pretende servir como base para la generación de librerías de estructuras de datos que sirvan para el cómputo concurrente.');